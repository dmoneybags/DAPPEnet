{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b31819e-edee-48cf-a08c-3ba31e34b609",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from IPython.display import clear_output\n",
    "%run GameFunctions.ipynb\n",
    "%run Player.ipynb\n",
    "%run Stats.ipynb\n",
    "%run TrainCritic.ipynb\n",
    "%run Breed.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07ed0ef6-bde9-4325-a691-ad603b94859d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActorCritic():\n",
    "    def genRewards(size, win):\n",
    "        rewardList = [0] * size\n",
    "        rewardList[size - 1] = 1 if win else -1\n",
    "        return tf.convert_to_tensor(np.array(rewardList), dtype=tf.float32)\n",
    "    def compute_loss(action_probs: tf.Tensor,  values: tf.Tensor,  returns: tf.Tensor) -> tf.Tensor:\n",
    "        eps = np.finfo(np.float32).eps.item()\n",
    "        returns = tf.cast(returns, float)\n",
    "        values = tf.cast(values, float)\n",
    "        values = ((values - tf.math.reduce_mean(values)) / \n",
    "                   (tf.math.reduce_std(values) + eps))\n",
    "        advantage = returns - values\n",
    "        action_log_probs = tf.math.log(action_probs)\n",
    "        actor_loss = -tf.math.reduce_sum(action_log_probs * advantage)\n",
    "        huber_loss = tf.keras.losses.Huber(reduction=tf.keras.losses.Reduction.SUM)\n",
    "        critic_loss = huber_loss(values, returns)\n",
    "        return actor_loss + critic_loss\n",
    "    def get_expected_return(rewards, gamma = 0.95, standardize = False) -> tf.Tensor:\n",
    "        eps = np.finfo(np.float32).eps.item()\n",
    "        rewardtensor = rewards\n",
    "        n = tf.shape(rewardtensor)[0]\n",
    "        returns = tf.TensorArray(dtype=tf.float32, size=0, dynamic_size=True)\n",
    "        # Start from the end of `rewards` and accumulate reward sums\n",
    "        # into the `returns` array\n",
    "        rewards = tf.cast(rewards[::-1], dtype=tf.float32)\n",
    "        discounted_sum = tf.constant(0.0)\n",
    "        discounted_sum_shape = discounted_sum.shape\n",
    "        for i in tf.range(n):\n",
    "            reward = rewards[i]\n",
    "            discounted_sum = reward + gamma * discounted_sum\n",
    "            discounted_sum.set_shape(discounted_sum_shape)\n",
    "            returns = returns.write(i, discounted_sum)\n",
    "        returns = returns.stack()[::-1]\n",
    "\n",
    "        if standardize:\n",
    "            returns = ((returns - tf.math.reduce_mean(returns)) / \n",
    "                   (tf.math.reduce_std(returns) + eps))\n",
    "        return returns\n",
    "    def trainStep(player1, player2):\n",
    "        with tf.GradientTape(persistent = True) as tape:\n",
    "            returnDict = GameFunctions.runGame(player1, player2, name1 = player1.name, name2 = player2.name)\n",
    "            \n",
    "            winner = returnDict[\"winner\"]\n",
    "            \n",
    "            returns1 = ActorCritic.get_expected_return(ActorCritic.genRewards(tf.size(returnDict['p1']['values']).numpy(), winner == 1))\n",
    "            returns2 = ActorCritic.get_expected_return(ActorCritic.genRewards(tf.size(returnDict['p2']['values']).numpy(), winner == 2))\n",
    "            \n",
    "            loss1 = ActorCritic.compute_loss(returnDict['p1']['probs'], returnDict['p1']['values'], returns1)\n",
    "            loss2 = ActorCritic.compute_loss(returnDict['p2']['probs'], returnDict['p2']['values'], returns2)\n",
    "        grads1 = tape.gradient(loss1, player1.net.trainable_variables)\n",
    "        grads2 = tape.gradient(loss2, player2.net.trainable_variables)\n",
    "        player1.opt.apply_gradients(zip(grads1, player1.net.trainable_variables))\n",
    "        player2.opt.apply_gradients(zip(grads2, player2.net.trainable_variables))\n",
    "        player1.updateStats(tf.size(returnDict['p1']['values']).numpy(), winner == 1)\n",
    "        player2.updateStats(tf.size(returnDict['p2']['values']).numpy(), winner == 2)\n",
    "        player1.save()\n",
    "        player2.save()\n",
    "        returnDict[\"p1\"] = player1\n",
    "        returnDict[\"p2\"] = player1\n",
    "        Statistics.writeStatistics()\n",
    "        return returnDict\n",
    "    def getCriticData(player1, player2):\n",
    "        CriticTrainingFunctions.formatInitialCsv()\n",
    "        returnDict = GameFunctions.runGame(player1.actor, player2.actor, player1.critic, player2.critic, name1 = player1.name, name2 = player2.name)\n",
    "        winner = returnDict['winner']\n",
    "        returns1 = ActorCritic.get_expected_return(ActorCritic.genRewards(tf.size(returnDict['p1']['values']).numpy(), winner == 1))\n",
    "        returns2 = ActorCritic.get_expected_return(ActorCritic.genRewards(tf.size(returnDict['p2']['values']).numpy(), winner == 2))\n",
    "        CriticTrainingFunctions.writeStates(returnDict['p1']['states'], returns1, returnDict['winner'] == 1, tf.size(returnDict['p1']['values']).numpy())\n",
    "        CriticTrainingFunctions.writeStates(returnDict['p2']['states'], returns2, returnDict['winner'] == 2, tf.size(returnDict['p2']['values']).numpy())\n",
    "        return int(tf.size(returnDict['p2']['values']).numpy())\n",
    "    def maxDamageTest(player):\n",
    "        returnDict = GameFunctions.testAgainstMaxDamage(player, name1 = player.name)\n",
    "        winner = returnDict[\"winner\"]\n",
    "        return winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87311644-581d-458e-85a6-93e2dd9f4c3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
